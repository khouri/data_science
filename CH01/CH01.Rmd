---
title: "Applied Predictive Modeling"
author: "Adilson Khouri"
date: "11/25/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# CH01 - Introduction 

The first chapter starts talking about the famous tradeoff between accuracy x interpretability, after that explains the foundations of model development. The first one is intuition about the problem, the second one is a deep knowledge of the problem context and the last one are the comnputer toolbox wich includes data vis, some models and data pre-processing.

## Data examples - used in competitions

###Music dataset 
This dataset is developed for a contest of predition model (like kaggle) there was six classes of possible output. The number of instances are $12495$ for wich 191 characteristics were determined. The six possible responses was not balanced. All the predictors were continuous, many are high correlated and with different scales of measurement.

###Grant Applications
This dataset was published in kaggle website and the goal is to predict the probability of sucess in a grant application. There was $8707$ grant applications from Melbourne University, $249$ predictors the response are binary (sucess or not sucess) the classes are balanced. The predictors contain variables: continuous, count and categorical  $83 \%$ of the data of the predictors were missing and the samples are not independent since the applicator can apply in more than one time between the ages of 2009 and 2010.

###Hepatic Injury
A pharmaceutical dataset used to develop a model to predict the probability of a compound causes hepatic injury. The number of instances are $281$ and there was $376$ predictors. The response was binary (cause injury or doesnt cause injury) and high unbalanced.

###Permeability
Another pharmaceutical dataset used to predict the probability of permeability (measure of how easy a compound can cross the membrane). The dataset contains $165$ compound's and $1107$ molecular fingerprint. The response is high skewed, the predictors are sparse and many predictors are stroingly associated.

###Fraudulent Financial Statements
This dataset contains $150$ data points used to train the model and $54$ to evaluate them. The final number of the predictors are $20$ there were a large class imbalance, the frequencies in the datasets are very different from the population. The number of predictors are large compared with the number of samples

##Dataset Comparison
Summarizing all the datasets, their values could be continuous, categorical or count, they have missing values and could be on different scales of measurement. Predictors from the same dataset may have a high correlation or association, indicating the predictor set contains numerically redundant information.

Furthermore predictors may be spars, meaning that a majority of samples contain the same information while a few contain unique information. Like the reponse the predictors can follow a symmetric or skewed distribution (for continuous data) or be balanced or unbalanced (for categorical predictors)

Diffent types of predictors can handle this predictor characteristics in different ways. For example, partial least squares naturally manages correlated predictors but is numerical more stable if the predictors are on similar scales. Recursive partitioning, on the othe hand, is unaffected by predictors in different scales but has a less stable partitioning structure when predictors are correlated.

Multiple linear regression cannot handle missing predictor information, but recursive partitioning can be used when predictors contain a moderate amount of missing information. In all these scenarios avoid the pre-processing step can be produce sub optimal models.

Finnaly all these datasets illustrates the relation between the number of samples and predictors. In the case where there are more samples than predictor all models can handle, its the happy way. The oposite case we cannot apply direct the multiple linear regression or linear discriminant analisys. On the other hand KNN and recursive partitioning can be used directly.

In summary we must have a detailed understanding of the predictors and the response for any data set prior to attempt to build any model to avoid a a less-than-optimal performance. Furthermore, most data sets require some pre-processing steps before starts the modeling.

##Overview of the book
The book is divided in four parts (I, II, III and IV), the first one is about pre-processing and ressampling. The secondpart is about measure the perfoprmance of a regression task and a case study. The part III is about measure performance of classification task. Finnaly the part IV is about feature selection techniques.

##Notation
n $=$ number of data points

P $=$ number of predictors

$y_i$ = the ith observed value of the outcome, $i = 1,2,3 \ldots$

$\hat{y_i}$ = the predicted outcome of the ith data point, $i = 1, \ldots n$

$\overline{y}=$ the average or sample mean of the n observed values of the outcome

$\mathbf{y}$ = a vector of all n outcome values

$x_{ij}$ = the value of the jth predictor for the ith data point, $i = 1, \ldots n$ and $j = 1, \ldots P$

$\overline{x_{j}}=$ the average or sample mean of the n data points for the jth predictor $j = 1, \ldots P$

$\mathbf{x_i}$ = a vector of P predictors for the ith data point, $i = 1, \ldots n$

$\mathbf{X}$ = a matrix of P predictors for all data points, this matrix has n rows and P columns

$\mathbf{X'}$ = transpose of $\mathbf{X}$, this matrix has P rows and n columns

Other notational guidelines udes in the equations:

C = the number of classes in a categorical outcome

$C_l$ = the value of lth class level

p = the probability of an event

$p_l$ = the probability of the lth event

Pr[.] = the probability of an event 

$\sum_{i=1}^{n}$ = the summation operator over the index i

$\Sigma$ = theoretical covariance matrix

E[.] the expected value of .

f(.) = a function of .

$\beta$ = an unknow or theoretical model coefficient 

$b$ = an estimated model coefficient based on a sample data point 
